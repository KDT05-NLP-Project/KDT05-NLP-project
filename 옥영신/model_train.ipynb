{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "        회차     시간    인물                                                 대사  \\\n0        1    0~5  # 상황  비오는 밤길을 달려가는 차량 헤드라이트 클로즈업 및 차창 밖으로 비가 내리고 있는 ...   \n1        1    0~5  # 상황            비가 떨어지는 자동차 바닥 아래로 스타워즈 오프닝 스타일의 자막 흘러감   \n2        1    0~5  나레이션  이 이야기는 암울했던 민족의 수난기와 격동기의 역사를 살다 갔던 영원한 야인 김두한...   \n3        1    0~5  나레이션  그러나 드라마의 원만한 진행을 위하여 시대와 역사적 상황을 운영하는 인물 일부분에서...   \n4        1    0~5  # 장소                                          어느 도예촌 전경   \n...    ...    ...   ...                                                ...   \n61619  124  60~65  # 사물                                       김두한 영정 클로즈 업   \n61620  124  60~65  나레이션  김두한 그는 일제 말 우리가 주권을 잃었던 식민지 시절부터 해방 이후 좌우익의 대립...   \n61621  124  60~65   최동열  나는 오랫동안 자네를 지켜보아 온 사람일세 자네는 자네답게 살았어 조선의 주먹 황제...   \n61622  124  60~65   최동열  나름대로 자네의 역사를 가지고 자네의 시대를 치열하고 열심히 살았다는 얘기야 뭐랄까...   \n61623  124  60~65  나레이션  야인시대 그렇다 그것은 바로 그가 몸바쳐 살아왔던 이 나라 격동기의 또 다른 역사의...   \n\n                                                     형태소   대사 레이블  형태소 레이블  \n0      ['비오', '밤길', '차량', '및', '차창', '밖', '비', '내리', ...  unknown  unknown  \n1      ['비', '떨어지', '자동차', '바닥', '스타워즈', '오프닝', '스타일'...  unknown  unknown  \n2      ['암울', '하', '았', '던', '민족', '수난', '격동기', '역사',...  unknown     민족주의  \n3      ['그러나', '하', 'ㄴ', '진행', '위하', '시대', '역사', '적',...  unknown  unknown  \n4                                ['어느', '도예', '촌', '전경']  unknown  unknown  \n...                                                  ...      ...      ...  \n61619                                 ['김두한', '영정', '업']  unknown  unknown  \n61620  ['김두한', '그', '일제', '말', '우리', '주권', '잃', '었', ...     국가주의     국가주의  \n61621  ['나', '오랫동안', '자네', '지켜보', '오', 'ㄴ', '사람', 'ㄹ'...  unknown     왕정주의  \n61622  ['나름', '자네', '역사', '고', '자네', '시대', '치열', '하',...  unknown  unknown  \n61623  ['그렇', '다', '그것', '그', '몸', '바치', '어', '았', '던...     국가주의  unknown  \n\n[61624 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>회차</th>\n      <th>시간</th>\n      <th>인물</th>\n      <th>대사</th>\n      <th>형태소</th>\n      <th>대사 레이블</th>\n      <th>형태소 레이블</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0~5</td>\n      <td># 상황</td>\n      <td>비오는 밤길을 달려가는 차량 헤드라이트 클로즈업 및 차창 밖으로 비가 내리고 있는 ...</td>\n      <td>['비오', '밤길', '차량', '및', '차창', '밖', '비', '내리', ...</td>\n      <td>unknown</td>\n      <td>unknown</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0~5</td>\n      <td># 상황</td>\n      <td>비가 떨어지는 자동차 바닥 아래로 스타워즈 오프닝 스타일의 자막 흘러감</td>\n      <td>['비', '떨어지', '자동차', '바닥', '스타워즈', '오프닝', '스타일'...</td>\n      <td>unknown</td>\n      <td>unknown</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0~5</td>\n      <td>나레이션</td>\n      <td>이 이야기는 암울했던 민족의 수난기와 격동기의 역사를 살다 갔던 영원한 야인 김두한...</td>\n      <td>['암울', '하', '았', '던', '민족', '수난', '격동기', '역사',...</td>\n      <td>unknown</td>\n      <td>민족주의</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0~5</td>\n      <td>나레이션</td>\n      <td>그러나 드라마의 원만한 진행을 위하여 시대와 역사적 상황을 운영하는 인물 일부분에서...</td>\n      <td>['그러나', '하', 'ㄴ', '진행', '위하', '시대', '역사', '적',...</td>\n      <td>unknown</td>\n      <td>unknown</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0~5</td>\n      <td># 장소</td>\n      <td>어느 도예촌 전경</td>\n      <td>['어느', '도예', '촌', '전경']</td>\n      <td>unknown</td>\n      <td>unknown</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>61619</th>\n      <td>124</td>\n      <td>60~65</td>\n      <td># 사물</td>\n      <td>김두한 영정 클로즈 업</td>\n      <td>['김두한', '영정', '업']</td>\n      <td>unknown</td>\n      <td>unknown</td>\n    </tr>\n    <tr>\n      <th>61620</th>\n      <td>124</td>\n      <td>60~65</td>\n      <td>나레이션</td>\n      <td>김두한 그는 일제 말 우리가 주권을 잃었던 식민지 시절부터 해방 이후 좌우익의 대립...</td>\n      <td>['김두한', '그', '일제', '말', '우리', '주권', '잃', '었', ...</td>\n      <td>국가주의</td>\n      <td>국가주의</td>\n    </tr>\n    <tr>\n      <th>61621</th>\n      <td>124</td>\n      <td>60~65</td>\n      <td>최동열</td>\n      <td>나는 오랫동안 자네를 지켜보아 온 사람일세 자네는 자네답게 살았어 조선의 주먹 황제...</td>\n      <td>['나', '오랫동안', '자네', '지켜보', '오', 'ㄴ', '사람', 'ㄹ'...</td>\n      <td>unknown</td>\n      <td>왕정주의</td>\n    </tr>\n    <tr>\n      <th>61622</th>\n      <td>124</td>\n      <td>60~65</td>\n      <td>최동열</td>\n      <td>나름대로 자네의 역사를 가지고 자네의 시대를 치열하고 열심히 살았다는 얘기야 뭐랄까...</td>\n      <td>['나름', '자네', '역사', '고', '자네', '시대', '치열', '하',...</td>\n      <td>unknown</td>\n      <td>unknown</td>\n    </tr>\n    <tr>\n      <th>61623</th>\n      <td>124</td>\n      <td>60~65</td>\n      <td>나레이션</td>\n      <td>야인시대 그렇다 그것은 바로 그가 몸바쳐 살아왔던 이 나라 격동기의 또 다른 역사의...</td>\n      <td>['그렇', '다', '그것', '그', '몸', '바치', '어', '았', '던...</td>\n      <td>국가주의</td>\n      <td>unknown</td>\n    </tr>\n  </tbody>\n</table>\n<p>61624 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize  \n",
    "from torchtext.vocab import Vocab \n",
    "\n",
    "script = pd.read_excel('../data/레이블링된 대본.xlsx')\n",
    "script"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T00:34:45.357639Z",
     "start_time": "2024-04-05T00:34:31.638259Z"
    }
   },
   "id": "86d5bda0ef81ceea",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "        회차     시간     인물                                                 대사  \\\n2        1    0~5   나레이션  이 이야기는 암울했던 민족의 수난기와 격동기의 역사를 살다 갔던 영원한 야인 김두한...   \n25       1    0~5    김두한              오늘 국회에서 마지막 발언이 있습니다 선생님 잠시만 나와보시겠습니까   \n27       1    0~5    최동열                                               국회에    \n37       1   5~10  공원관리인   여러분네들 아니 국회에서 여기서 똥 퍼다가 뭐한다요 아니 이 밤중에 도대체 뭘들 한다요   \n40       1   5~10    정대발  쉬이 조용히 저 인분은 피흘려 나라를 지키신 애국지사 분들께서 기미년 삼월 일일날에...   \n...    ...    ...    ...                                                ...   \n61588  124  50~55   나레이션  김두한은 오물사건에서 병보석으로 석방된 이후 청와대에서 박정희를 만났다고 한다 그 ...   \n61606  124  55~60     두한  용서해 주십시오 그게 다 애국을 하느라고 그렇게 됐습니다 용서해 주십시오 용서해 주...   \n61616  124  55~60   나레이션  천구백칠십이년 십일월 이십일일 김두한은 오랜 지병이었던 고혈압으로 쓰러졌다 향년 오...   \n61620  124  60~65   나레이션  김두한 그는 일제 말 우리가 주권을 잃었던 식민지 시절부터 해방 이후 좌우익의 대립...   \n61621  124  60~65    최동열  나는 오랫동안 자네를 지켜보아 온 사람일세 자네는 자네답게 살았어 조선의 주먹 황제...   \n\n                                                     형태소   대사 레이블 형태소 레이블  \n2      ['암울', '하', '았', '던', '민족', '수난', '격동기', '역사',...  unknown    민족주의  \n25     ['오늘', '국회', '마지막', '발언', '있', '습니다', '선생님', '...  unknown    민주주의  \n27                                                ['국회']  unknown    민주주의  \n37     ['네', '들', '국회', '서', '똥', '퍼다', '뭐', '하', 'ㄴ'...  unknown    민주주의  \n40     ['조용히', '저', '피', '흘리', '어', '지키', '시', 'ㄴ', '...     민족주의    민족주의  \n...                                                  ...      ...     ...  \n61588  ['김두한', '오물', '사건', '병', '보석', '석방', '되', 'ㄴ',...  unknown    국가주의  \n61606  ['용서', '하', '주', '시', 'ㅂ오', '그', '게', '다', '애국...  unknown    민족주의  \n61616  ['천', '구백', '칠십', '년', '십', '일월', '일', 'ㄹ', '김...     국가주의    국가주의  \n61620  ['김두한', '그', '일제', '말', '우리', '주권', '잃', '었', ...     국가주의    국가주의  \n61621  ['나', '오랫동안', '자네', '지켜보', '오', 'ㄴ', '사람', 'ㄹ'...  unknown    왕정주의  \n\n[6261 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>회차</th>\n      <th>시간</th>\n      <th>인물</th>\n      <th>대사</th>\n      <th>형태소</th>\n      <th>대사 레이블</th>\n      <th>형태소 레이블</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0~5</td>\n      <td>나레이션</td>\n      <td>이 이야기는 암울했던 민족의 수난기와 격동기의 역사를 살다 갔던 영원한 야인 김두한...</td>\n      <td>['암울', '하', '았', '던', '민족', '수난', '격동기', '역사',...</td>\n      <td>unknown</td>\n      <td>민족주의</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>1</td>\n      <td>0~5</td>\n      <td>김두한</td>\n      <td>오늘 국회에서 마지막 발언이 있습니다 선생님 잠시만 나와보시겠습니까</td>\n      <td>['오늘', '국회', '마지막', '발언', '있', '습니다', '선생님', '...</td>\n      <td>unknown</td>\n      <td>민주주의</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>1</td>\n      <td>0~5</td>\n      <td>최동열</td>\n      <td>국회에</td>\n      <td>['국회']</td>\n      <td>unknown</td>\n      <td>민주주의</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>1</td>\n      <td>5~10</td>\n      <td>공원관리인</td>\n      <td>여러분네들 아니 국회에서 여기서 똥 퍼다가 뭐한다요 아니 이 밤중에 도대체 뭘들 한다요</td>\n      <td>['네', '들', '국회', '서', '똥', '퍼다', '뭐', '하', 'ㄴ'...</td>\n      <td>unknown</td>\n      <td>민주주의</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>1</td>\n      <td>5~10</td>\n      <td>정대발</td>\n      <td>쉬이 조용히 저 인분은 피흘려 나라를 지키신 애국지사 분들께서 기미년 삼월 일일날에...</td>\n      <td>['조용히', '저', '피', '흘리', '어', '지키', '시', 'ㄴ', '...</td>\n      <td>민족주의</td>\n      <td>민족주의</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>61588</th>\n      <td>124</td>\n      <td>50~55</td>\n      <td>나레이션</td>\n      <td>김두한은 오물사건에서 병보석으로 석방된 이후 청와대에서 박정희를 만났다고 한다 그 ...</td>\n      <td>['김두한', '오물', '사건', '병', '보석', '석방', '되', 'ㄴ',...</td>\n      <td>unknown</td>\n      <td>국가주의</td>\n    </tr>\n    <tr>\n      <th>61606</th>\n      <td>124</td>\n      <td>55~60</td>\n      <td>두한</td>\n      <td>용서해 주십시오 그게 다 애국을 하느라고 그렇게 됐습니다 용서해 주십시오 용서해 주...</td>\n      <td>['용서', '하', '주', '시', 'ㅂ오', '그', '게', '다', '애국...</td>\n      <td>unknown</td>\n      <td>민족주의</td>\n    </tr>\n    <tr>\n      <th>61616</th>\n      <td>124</td>\n      <td>55~60</td>\n      <td>나레이션</td>\n      <td>천구백칠십이년 십일월 이십일일 김두한은 오랜 지병이었던 고혈압으로 쓰러졌다 향년 오...</td>\n      <td>['천', '구백', '칠십', '년', '십', '일월', '일', 'ㄹ', '김...</td>\n      <td>국가주의</td>\n      <td>국가주의</td>\n    </tr>\n    <tr>\n      <th>61620</th>\n      <td>124</td>\n      <td>60~65</td>\n      <td>나레이션</td>\n      <td>김두한 그는 일제 말 우리가 주권을 잃었던 식민지 시절부터 해방 이후 좌우익의 대립...</td>\n      <td>['김두한', '그', '일제', '말', '우리', '주권', '잃', '었', ...</td>\n      <td>국가주의</td>\n      <td>국가주의</td>\n    </tr>\n    <tr>\n      <th>61621</th>\n      <td>124</td>\n      <td>60~65</td>\n      <td>최동열</td>\n      <td>나는 오랫동안 자네를 지켜보아 온 사람일세 자네는 자네답게 살았어 조선의 주먹 황제...</td>\n      <td>['나', '오랫동안', '자네', '지켜보', '오', 'ㄴ', '사람', 'ㄹ'...</td>\n      <td>unknown</td>\n      <td>왕정주의</td>\n    </tr>\n  </tbody>\n</table>\n<p>6261 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 형태소 레이블에서 unknown인 행 삭제\n",
    "script = script[script['형태소 레이블'] != 'unknown']\n",
    "script"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T00:35:25.339304Z",
     "start_time": "2024-04-05T00:35:25.311163Z"
    }
   },
   "id": "b0e9dde714f521c7",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 한국어 토크나이저 임포트\n",
    "from konlpy.tag import Komoran \n",
    "\n",
    "# 사용자 정의 vocab 클래스 정의\n",
    "class Vocab:\n",
    "    def __init__(self, tokens, min_freq=1):\n",
    "        self.tokens = tokens\n",
    "        self.token_freq = {token: tokens.count(token) for token in set(tokens)}\n",
    "        self.token_to_idx = {token: idx for idx, token in enumerate([token for token, freq in self.token_freq.items() if freq >= min_freq])}\n",
    "        self.idx_to_token = {idx: token for token, idx in self.token_to_idx.items()}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.token_to_idx)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T00:35:44.457392Z",
     "start_time": "2024-04-05T00:35:44.411375Z"
    }
   },
   "id": "1b83c5005c04fcbc",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "import re\n",
    "from soynlp.normalizer import emoticon_normalize\n",
    "\n",
    "# 불용어 제거 함수\n",
    "def remove_unnecessary_sounds(morpheme):\n",
    "    # 이모티콘 정규화 and 웃음 소리나 의미없는 소리 제거\n",
    "    cleaned_morpheme = emoticon_normalize(morpheme, num_repeats=2) if morpheme not in ['하하', '하하하', '흠', '음', '허허', '음하하', '흐흐흐', '흐', '흐흐', '으응', '허허허', '으', '으허허', '으허'] else ''\n",
    "    return cleaned_morpheme\n",
    "\n",
    "# 토크나이저\n",
    "tokenizer = Komoran()\n",
    "\n",
    "vocab_tokens = []\n",
    "for _, row in script.iterrows():\n",
    "    tokens = tokenizer.morphs(row['형태소'])\n",
    "    cleaned_tokens = [remove_unnecessary_sounds(token) for token in tokens]\n",
    "    vocab_tokens.extend(cleaned_tokens)\n",
    "\n",
    "# unk 추가\n",
    "vocab_tokens.append('<unk>')\n",
    "\n",
    "vocab = Vocab(vocab_tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T00:38:45.738867Z",
     "start_time": "2024-04-05T00:37:38.869350Z"
    }
   },
   "id": "625616994e6fe11d",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # 데이터 전처리 및 Dataset 생성\n",
    "# texts = []\n",
    "# labels = []\n",
    "# for _, row in script.iterrows():\n",
    "#     text = [vocab.token_to_idx.get(token, vocab.token_to_idx['<unk>']) for token in tokenizer.morphs(row['대사'])]\n",
    "#     label = row['레이블']\n",
    "#     texts.append(text)\n",
    "#     labels.append(label)\n",
    "#     \n",
    "# # 데이터셋 분리\n",
    "# train_texts = texts[:int(0.8*len(texts))]\n",
    "# train_labels = labels[:int(0.8*len(labels))]\n",
    "# test_texts = texts[int(0.8*len(texts)):]\n",
    "# test_labels = labels[int(0.8*len(labels)):]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T06:27:33.293263Z",
     "start_time": "2024-04-04T06:27:33.287826Z"
    }
   },
   "id": "cd4ca0382fda266d",
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "embed_size = 64\n",
    "hidden_size = 128\n",
    "num_classes = 9  # 클래스 개수\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 32"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T00:39:02.920095Z",
     "start_time": "2024-04-05T00:39:02.906227Z"
    }
   },
   "id": "90a1b4e5cdcfa936",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class ScriptDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        return text, label\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        texts, labels = zip(*batch)\n",
    "        texts = pad_sequence([torch.tensor(text) for text in texts], batch_first=True)\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "        return texts, labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T00:39:14.321968Z",
     "start_time": "2024-04-05T00:39:14.304594Z"
    }
   },
   "id": "62d42bd76d0cd747",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# 레이블 매핑\n",
    "label_map = {\n",
    "    'unknown': 0, \n",
    "    '왕정주의': 1, \n",
    "    '민족주의': 2, \n",
    "    '사회주의': 3, \n",
    "    '자유주의': 4, \n",
    "    '반공주의': 5, \n",
    "    '민주주의': 6, \n",
    "    '국가주의': 7,\n",
    "    '제국주의': 8\n",
    "}\n",
    "\n",
    "# 데이터 전처리 및 Dataset 생성\n",
    "texts = []\n",
    "labels = []\n",
    "for _, row in script.iterrows():\n",
    "    text = [vocab.token_to_idx.get(token, vocab.token_to_idx['<unk>']) for token in tokenizer.morphs(row['형태소'])]\n",
    "    label = label_map[row['형태소 레이블']]\n",
    "    texts.append(text)\n",
    "    labels.append(label)\n",
    "\n",
    "train_dataset = ScriptDataset(texts[:int(0.8*len(texts))], labels[:int(0.8*len(labels))])\n",
    "test_dataset = ScriptDataset(texts[int(0.8*len(texts)):], labels[int(0.8*len(labels)):])\n",
    "\n",
    "# 데이터 로더 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=test_dataset.collate_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T00:39:45.234572Z",
     "start_time": "2024-04-05T00:39:38.525934Z"
    }
   },
   "id": "52e8019ef3a48833",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# RNN 모델 정의\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_classes):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.RNN(embed_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.rnn(x)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x\n",
    "\n",
    "# 모델, 손실함수, 옵티마이저 초기화\n",
    "model = RNNModel(len(vocab), embed_size, hidden_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T00:40:06.515243Z",
     "start_time": "2024-04-05T00:40:04.323038Z"
    }
   },
   "id": "2eea250acb423def",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.4832, Accuracy: 21.88%\n",
      "Epoch 2/10, Loss: 1.7240, Accuracy: 9.38%\n",
      "Epoch 3/10, Loss: 1.3931, Accuracy: 21.88%\n",
      "Epoch 4/10, Loss: 1.4894, Accuracy: 21.88%\n",
      "Epoch 5/10, Loss: 1.3934, Accuracy: 28.12%\n",
      "Epoch 6/10, Loss: 1.4624, Accuracy: 21.88%\n",
      "Epoch 7/10, Loss: 1.3672, Accuracy: 25.00%\n",
      "Epoch 8/10, Loss: 1.1479, Accuracy: 28.12%\n",
      "Epoch 9/10, Loss: 1.4522, Accuracy: 21.88%\n",
      "Epoch 10/10, Loss: 1.6196, Accuracy: 9.38%\n"
     ]
    }
   ],
   "source": [
    "# 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    for texts, labels in train_loader:\n",
    "        outputs = model(texts)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}, Accuracy: {100 * (outputs.argmax(1) == labels).sum().item() / batch_size:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T00:41:56.799471Z",
     "start_time": "2024-04-05T00:40:18.905716Z"
    }
   },
   "id": "b9593758e57295c7",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 45.33%\n"
     ]
    }
   ],
   "source": [
    "# 평가\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for texts, labels in test_loader:\n",
    "        outputs = model(texts)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy: {100 * correct / total:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T00:43:24.416826Z",
     "start_time": "2024-04-05T00:43:24.132238Z"
    }
   },
   "id": "15003d8fa460d766",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Inverse label mapping\n",
    "idx_to_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "def predict_ideology(model, sentence):\n",
    "    model.eval()\n",
    "    tokenized = [vocab.token_to_idx.get(token, vocab.token_to_idx['<unk>']) for token in tokenizer.morphs(sentence)]\n",
    "    tensor = torch.LongTensor(tokenized).unsqueeze(0)\n",
    "    prediction = model(tensor)\n",
    "    _, pred = torch.max(prediction, 1)\n",
    "    return idx_to_label_map[pred.item()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T01:21:03.700353Z",
     "start_time": "2024-04-05T01:21:03.695127Z"
    }
   },
   "id": "891ce5beb4c7f0e4",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'민족주의'"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ideology(model, '정말로 기다리시던 분들입니다! 본인 심영과 문외봉 동무를 소개하겠습니다!')"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-05T01:21:08.196767Z",
     "start_time": "2024-04-05T01:21:08.188397Z"
    }
   },
   "id": "initial_id",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "embed_size = 64\n",
    "hidden_size = 32 # 줄임   \n",
    "num_classes = 9  # 클래스 개수\n",
    "num_epochs = 10\n",
    "learning_rate = 0.0001 # 학습률 조정\n",
    "batch_size = 64 # 배치 사이즈 증가"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T04:17:55.974420Z",
     "start_time": "2024-04-05T04:17:55.956061Z"
    }
   },
   "id": "6781039eb9052d11",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model2 = RNNModel(len(vocab), embed_size, hidden_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T04:17:57.157857Z",
     "start_time": "2024-04-05T04:17:57.140010Z"
    }
   },
   "id": "22a46b2bff491703",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.5190, Accuracy: 12.50%\n",
      "Epoch 2/10, Loss: 1.7043, Accuracy: 7.81%\n",
      "Epoch 3/10, Loss: 1.4467, Accuracy: 7.81%\n",
      "Epoch 4/10, Loss: 1.5693, Accuracy: 7.81%\n",
      "Epoch 5/10, Loss: 1.3822, Accuracy: 15.62%\n",
      "Epoch 6/10, Loss: 1.7382, Accuracy: 7.81%\n",
      "Epoch 7/10, Loss: 1.5403, Accuracy: 9.38%\n",
      "Epoch 8/10, Loss: 1.6934, Accuracy: 10.94%\n",
      "Epoch 9/10, Loss: 1.3748, Accuracy: 12.50%\n",
      "Epoch 10/10, Loss: 1.5048, Accuracy: 10.94%\n"
     ]
    }
   ],
   "source": [
    "# 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    for texts, labels in train_loader:\n",
    "        outputs = model2(texts)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}, Accuracy: {100 * (outputs.argmax(1) == labels).sum().item() / batch_size:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T04:18:41.731552Z",
     "start_time": "2024-04-05T04:18:02.493414Z"
    }
   },
   "id": "a05456761a9fb7b2",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 45.65%\n"
     ]
    }
   ],
   "source": [
    "# 평가\n",
    "model2.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for texts, labels in test_loader:\n",
    "        outputs = model2(texts)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy: {100 * correct / total:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T04:26:50.098659Z",
     "start_time": "2024-04-05T04:26:49.954303Z"
    }
   },
   "id": "831112c9e618b2ea",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'사회주의'"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ideology(model, '정말 위대합니다 선생!')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T04:24:30.853452Z",
     "start_time": "2024-04-05T04:24:30.844103Z"
    }
   },
   "id": "954f76e089cbbb2d",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_classes, num_layers, dropout_rate):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.gru = nn.GRU(embed_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.gru(x)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T00:45:02.905970Z",
     "start_time": "2024-04-05T00:45:02.899363Z"
    }
   },
   "id": "1fde0392198bbd8f",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "embed_size = 64\n",
    "hidden_size = 32 # 줄임\n",
    "num_classes = 9  # 클래스 개수\n",
    "num_epochs = 10\n",
    "learning_rate = 0.0001  # 조정된 학습률\n",
    "batch_size = 64 # 늘림\n",
    "num_layers = 2  # GRU 층 수\n",
    "dropout_rate = 0.5  # 드롭아웃 비율\n",
    "\n",
    "# 모델, 손실함수, 옵티마이저 초기화\n",
    "modelG = GRUModel(len(vocab), embed_size, hidden_size, num_classes, num_layers, dropout_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# adamw로 변경\n",
    "optimizer = torch.optim.AdamW(modelG.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T04:36:11.301753Z",
     "start_time": "2024-04-05T04:36:11.284976Z"
    }
   },
   "id": "69febfefca46828d",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.8963, Accuracy: 7.81%\n",
      "Epoch 2/10, Loss: 1.6433, Accuracy: 9.38%\n",
      "Epoch 3/10, Loss: 1.5039, Accuracy: 9.38%\n",
      "Epoch 4/10, Loss: 1.3531, Accuracy: 12.50%\n",
      "Epoch 5/10, Loss: 2.2583, Accuracy: 9.38%\n",
      "Epoch 6/10, Loss: 1.5728, Accuracy: 7.81%\n",
      "Epoch 7/10, Loss: 1.4942, Accuracy: 9.38%\n",
      "Epoch 8/10, Loss: 1.3544, Accuracy: 9.38%\n",
      "Epoch 9/10, Loss: 1.6905, Accuracy: 7.81%\n",
      "Epoch 10/10, Loss: 1.5202, Accuracy: 6.25%\n"
     ]
    }
   ],
   "source": [
    "# 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    for texts, labels in train_loader:\n",
    "        outputs = modelG(texts)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}, Accuracy: {100 * (outputs.argmax(1) == labels).sum().item() / batch_size:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T04:38:37.025189Z",
     "start_time": "2024-04-05T04:36:12.742707Z"
    }
   },
   "id": "b8617bdb4757b8b0",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 45.97%\n"
     ]
    }
   ],
   "source": [
    "# 평가\n",
    "modelG.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for texts, labels in test_loader:\n",
    "        outputs = modelG(texts)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy: {100 * correct / total:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T04:39:28.750658Z",
     "start_time": "2024-04-05T04:39:27.703586Z"
    }
   },
   "id": "841275d247d33b7c",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'사회주의'"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ideology(modelG, '우리는 투표 없이도 불의한 권력을 민주적으로 몰아낸 자랑스러운 역사를 기억합니다')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T04:40:08.688580Z",
     "start_time": "2024-04-05T04:40:08.663025Z"
    }
   },
   "id": "83a14d6c98ea38d",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "embed_size = 64\n",
    "hidden_size = 32 # 줄임\n",
    "num_classes = 9 \n",
    "num_epochs = 100  # 에폭 수 증가 \n",
    "learning_rate = 0.0001  # 조정된 학습률\n",
    "batch_size = 64 # 늘림\n",
    "num_layers = 2  # GRU 층 수\n",
    "dropout_rate = 0.5  # 드롭아웃 비율\n",
    "\n",
    "# 모델, 손실함수, 옵티마이저 초기화\n",
    "modelR = GRUModel(len(vocab), embed_size, hidden_size, num_classes, num_layers, dropout_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(modelR.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T04:47:31.673109Z",
     "start_time": "2024-04-05T04:47:31.662456Z"
    }
   },
   "id": "2d304dca435a445c",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 1.8674, Accuracy: 7.81%, Learning rate: 0.0001\n",
      "Epoch 2/100, Loss: 1.7727, Accuracy: 6.25%, Learning rate: 0.0001\n",
      "Epoch 3/100, Loss: 1.7335, Accuracy: 7.81%, Learning rate: 0.0001\n",
      "Epoch 4/100, Loss: 1.4117, Accuracy: 10.94%, Learning rate: 0.0001\n",
      "Epoch 5/100, Loss: 1.5685, Accuracy: 7.81%, Learning rate: 0.0001\n",
      "Epoch 6/100, Loss: 1.5706, Accuracy: 6.25%, Learning rate: 0.0001\n",
      "Epoch 7/100, Loss: 2.1440, Accuracy: 4.69%, Learning rate: 0.0001\n",
      "Epoch 8/100, Loss: 1.8836, Accuracy: 4.69%, Learning rate: 0.0001\n",
      "Epoch 9/100, Loss: 1.8417, Accuracy: 6.25%, Learning rate: 0.0001\n",
      "Epoch 10/100, Loss: 1.4877, Accuracy: 12.50%, Learning rate: 0.0001\n",
      "Epoch 11/100, Loss: 1.4986, Accuracy: 7.81%, Learning rate: 0.0001\n",
      "Epoch 12/100, Loss: 1.4388, Accuracy: 10.94%, Learning rate: 0.0001\n",
      "Epoch 13/100, Loss: 1.4617, Accuracy: 12.50%, Learning rate: 0.0001\n",
      "Epoch 14/100, Loss: 1.6387, Accuracy: 9.38%, Learning rate: 0.0001\n",
      "Epoch 15/100, Loss: 1.5337, Accuracy: 12.50%, Learning rate: 0.0001\n",
      "Epoch 16/100, Loss: 1.7814, Accuracy: 4.69%, Learning rate: 0.0001\n",
      "Epoch 17/100, Loss: 1.6025, Accuracy: 10.94%, Learning rate: 0.0001\n",
      "Epoch 18/100, Loss: 1.4698, Accuracy: 7.81%, Learning rate: 0.0001\n",
      "Epoch 19/100, Loss: 1.6296, Accuracy: 6.25%, Learning rate: 0.0001\n",
      "Epoch 20/100, Loss: 1.1371, Accuracy: 14.06%, Learning rate: 0.0001\n",
      "Epoch 21/100, Loss: 1.7817, Accuracy: 7.81%, Learning rate: 0.0001\n",
      "Epoch 22/100, Loss: 1.4296, Accuracy: 9.38%, Learning rate: 0.0001\n",
      "Epoch 23/100, Loss: 1.6318, Accuracy: 12.50%, Learning rate: 0.0001\n",
      "Epoch 24/100, Loss: 1.6123, Accuracy: 9.38%, Learning rate: 0.0001\n",
      "Epoch 25/100, Loss: 1.3583, Accuracy: 15.62%, Learning rate: 0.0001\n",
      "Epoch 26/100, Loss: 1.8571, Accuracy: 6.25%, Learning rate: 0.0001\n",
      "Epoch 27/100, Loss: 1.3977, Accuracy: 14.06%, Learning rate: 0.0001\n",
      "Epoch 28/100, Loss: 1.5412, Accuracy: 7.81%, Learning rate: 0.0001\n",
      "Epoch 29/100, Loss: 1.2687, Accuracy: 12.50%, Learning rate: 0.0001\n",
      "Epoch 30/100, Loss: 1.6042, Accuracy: 4.69%, Learning rate: 1e-05\n",
      "Epoch 31/100, Loss: 1.3920, Accuracy: 14.06%, Learning rate: 1e-05\n",
      "Epoch 32/100, Loss: 1.4734, Accuracy: 6.25%, Learning rate: 1e-05\n",
      "Epoch 33/100, Loss: 1.5112, Accuracy: 6.25%, Learning rate: 1e-05\n",
      "Epoch 34/100, Loss: 1.3806, Accuracy: 9.38%, Learning rate: 1e-05\n",
      "Epoch 35/100, Loss: 1.6890, Accuracy: 6.25%, Learning rate: 1e-05\n",
      "Epoch 36/100, Loss: 1.7611, Accuracy: 6.25%, Learning rate: 1e-05\n",
      "Epoch 37/100, Loss: 1.5736, Accuracy: 10.94%, Learning rate: 1e-05\n",
      "Epoch 38/100, Loss: 1.5198, Accuracy: 7.81%, Learning rate: 1e-05\n",
      "Epoch 39/100, Loss: 1.5318, Accuracy: 7.81%, Learning rate: 1e-05\n",
      "Epoch 40/100, Loss: 1.6475, Accuracy: 7.81%, Learning rate: 1e-05\n",
      "Epoch 41/100, Loss: 1.6689, Accuracy: 6.25%, Learning rate: 1e-05\n",
      "Epoch 42/100, Loss: 1.5163, Accuracy: 7.81%, Learning rate: 1e-05\n",
      "Epoch 43/100, Loss: 1.8026, Accuracy: 6.25%, Learning rate: 1e-05\n",
      "Epoch 44/100, Loss: 1.4670, Accuracy: 10.94%, Learning rate: 1e-05\n",
      "Epoch 45/100, Loss: 1.5890, Accuracy: 9.38%, Learning rate: 1e-05\n",
      "Epoch 46/100, Loss: 2.1490, Accuracy: 6.25%, Learning rate: 1e-05\n",
      "Epoch 47/100, Loss: 1.4673, Accuracy: 9.38%, Learning rate: 1e-05\n",
      "Epoch 48/100, Loss: 1.5585, Accuracy: 6.25%, Learning rate: 1e-05\n",
      "Epoch 49/100, Loss: 1.8545, Accuracy: 9.38%, Learning rate: 1e-05\n",
      "Epoch 50/100, Loss: 1.5932, Accuracy: 6.25%, Learning rate: 1e-05\n",
      "Epoch 51/100, Loss: 1.4067, Accuracy: 9.38%, Learning rate: 1e-05\n",
      "Epoch 52/100, Loss: 1.5608, Accuracy: 4.69%, Learning rate: 1e-05\n",
      "Epoch 53/100, Loss: 1.6256, Accuracy: 4.69%, Learning rate: 1e-05\n",
      "Epoch 54/100, Loss: 1.5265, Accuracy: 9.38%, Learning rate: 1e-05\n",
      "Epoch 55/100, Loss: 1.7088, Accuracy: 6.25%, Learning rate: 1e-05\n",
      "Epoch 56/100, Loss: 1.5691, Accuracy: 7.81%, Learning rate: 1e-05\n",
      "Epoch 57/100, Loss: 1.3726, Accuracy: 14.06%, Learning rate: 1e-05\n",
      "Epoch 58/100, Loss: 1.2722, Accuracy: 12.50%, Learning rate: 1e-05\n",
      "Epoch 59/100, Loss: 1.3968, Accuracy: 10.94%, Learning rate: 1e-05\n",
      "Epoch 60/100, Loss: 1.9655, Accuracy: 3.12%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 61/100, Loss: 1.2226, Accuracy: 9.38%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 62/100, Loss: 1.3608, Accuracy: 10.94%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 63/100, Loss: 1.3877, Accuracy: 14.06%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 64/100, Loss: 1.6848, Accuracy: 9.38%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 65/100, Loss: 1.3904, Accuracy: 12.50%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 66/100, Loss: 1.6076, Accuracy: 7.81%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 67/100, Loss: 1.6374, Accuracy: 9.38%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 68/100, Loss: 1.5206, Accuracy: 9.38%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 69/100, Loss: 1.4205, Accuracy: 10.94%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 70/100, Loss: 1.6358, Accuracy: 9.38%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 71/100, Loss: 1.7142, Accuracy: 6.25%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 72/100, Loss: 1.6096, Accuracy: 12.50%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 73/100, Loss: 1.5552, Accuracy: 9.38%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 74/100, Loss: 1.5279, Accuracy: 9.38%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 75/100, Loss: 1.4402, Accuracy: 9.38%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 76/100, Loss: 1.3251, Accuracy: 14.06%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 77/100, Loss: 1.3211, Accuracy: 14.06%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 78/100, Loss: 1.6331, Accuracy: 9.38%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 79/100, Loss: 1.5240, Accuracy: 9.38%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 80/100, Loss: 1.6348, Accuracy: 9.38%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 81/100, Loss: 1.3807, Accuracy: 9.38%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 82/100, Loss: 1.4391, Accuracy: 9.38%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 83/100, Loss: 1.4894, Accuracy: 10.94%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 84/100, Loss: 1.5023, Accuracy: 7.81%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 85/100, Loss: 1.6723, Accuracy: 9.38%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 86/100, Loss: 1.7276, Accuracy: 14.06%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 87/100, Loss: 1.6736, Accuracy: 9.38%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 88/100, Loss: 1.6040, Accuracy: 6.25%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 89/100, Loss: 1.7614, Accuracy: 7.81%, Learning rate: 1.0000000000000002e-06\n",
      "Epoch 90/100, Loss: 1.6478, Accuracy: 12.50%, Learning rate: 1.0000000000000002e-07\n",
      "Epoch 91/100, Loss: 1.4910, Accuracy: 6.25%, Learning rate: 1.0000000000000002e-07\n",
      "Epoch 92/100, Loss: 1.3143, Accuracy: 9.38%, Learning rate: 1.0000000000000002e-07\n",
      "Epoch 93/100, Loss: 1.7550, Accuracy: 9.38%, Learning rate: 1.0000000000000002e-07\n",
      "Epoch 94/100, Loss: 1.6750, Accuracy: 9.38%, Learning rate: 1.0000000000000002e-07\n",
      "Epoch 95/100, Loss: 1.3912, Accuracy: 12.50%, Learning rate: 1.0000000000000002e-07\n",
      "Epoch 96/100, Loss: 1.4970, Accuracy: 10.94%, Learning rate: 1.0000000000000002e-07\n",
      "Epoch 97/100, Loss: 1.3980, Accuracy: 12.50%, Learning rate: 1.0000000000000002e-07\n",
      "Epoch 98/100, Loss: 1.5470, Accuracy: 12.50%, Learning rate: 1.0000000000000002e-07\n",
      "Epoch 99/100, Loss: 1.5069, Accuracy: 7.81%, Learning rate: 1.0000000000000002e-07\n",
      "Epoch 100/100, Loss: 1.4329, Accuracy: 15.62%, Learning rate: 1.0000000000000002e-07\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# 스케줄러 초기화\n",
    "scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    for texts, labels in train_loader:\n",
    "        outputs = modelR(texts)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 스케줄러 스텝 업데이트\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}, Accuracy: {100 * (outputs.argmax(1) == labels).sum().item() / batch_size:.2f}%, Learning rate: {scheduler.get_last_lr()[0]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T05:14:09.790072Z",
     "start_time": "2024-04-05T04:47:39.384950Z"
    }
   },
   "id": "c97009163bdfb308",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 45.89%\n"
     ]
    }
   ],
   "source": [
    "# 평가\n",
    "modelR.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for texts, labels in test_loader:\n",
    "        outputs = modelR(texts)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy: {100 * correct / total:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T05:15:06.046984Z",
     "start_time": "2024-04-05T05:15:05.042018Z"
    }
   },
   "id": "9e64ba485cc74553",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'사회주의'"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ideology(modelR, '고종황제 폐하 만세!')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T05:15:07.627054Z",
     "start_time": "2024-04-05T05:15:07.609268Z"
    }
   },
   "id": "b3f441510dd88237",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c047bb4fc304abd5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
